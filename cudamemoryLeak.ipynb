{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "startjulia1.5.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "julia-1.5",
      "display_name": "Julia 1.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daryoush/CudaAndFluxExperiments/blob/main/cudamemoryLeak.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjWDviG9ntWm"
      },
      "source": [
        "Control m m will convert a code cell to a text cell. Control m y will convert a text cell to a code cell.\n",
        "\n",
        "The full list of keyboard shortcuts is available under 'Keyboard shortcuts' in the Tools menu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMSuTc3pDlHv"
      },
      "source": [
        "### NOTE THIS WORKS AS PYTHON, IT ONLY WORKS WHEN THE RUNTIME COMPLAINS ABOUT JULIA RUNTIME, SO IT REVERTS TO PYTHON. AFTER JULIA IS INSTALLED, CHANGE TO JULIA RUNTIME\n",
        "\n",
        "!curl -sSL \"https://julialang-s3.julialang.org/bin/linux/x64/1.5/julia-1.5.3-linux-x86_64.tar.gz\" -o julia.tar.gz\n",
        "!tar -xzf julia.tar.gz -C /usr --strip-components 1\n",
        "!rm -rf julia.tar.gz*\n",
        "!julia -e 'using Pkg; pkg\"add IJulia; precompile\"'\n",
        "!julia -e 'using Pkg; Pkg.add([ \"CUDA\"]);Pkg.precompile()'\n",
        "# \"Flux\",\"Zygote\",\"Profile\", \"TensorBoardLogger\", \"Logging\",\\\n",
        "#    \"Random\", \"DataStructures\", \"Transformers\",\"Statistics\", \"BenchmarkTools\"\\\n",
        "\n",
        "!echo \"DONE\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoZnMwsrCNZn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e84c47bb-b8db-4711-f600-ed0d82bb1633"
      },
      "source": [
        "  [1,2,3]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3-element Array{Int64,1}:\n",
              " 1\n",
              " 2\n",
              " 3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrtJwtCUgCjX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01c0df83-c2f8-48cf-c4fc-07dc4b8ccad8"
      },
      "source": [
        "using Pkg\n",
        "Pkg.add([\"BenchmarkTools\"])\n",
        "using CUDA\n",
        "using Logging"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.5/Project.toml`\n",
            "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.5/Manifest.toml`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQlpeR9wNOi8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c7ab4cc-d682-4552-ecd7-12411012c940"
      },
      "source": [
        "using BenchmarkTools\n",
        "\n",
        "M = rand(2048, 2048)\n",
        "@benchmark M^2\n",
        "\n",
        "if ENV[\"COLAB_GPU\"] == \"1\"\n",
        "\n",
        "    M_gpu = cu(M)\n",
        "    @benchmark CUDA.@sync M_gpu^2\n",
        "else\n",
        "    println(\"No GPU found.\")\n",
        "end"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "┌ Info: Precompiling BenchmarkTools [6e4b80f9-dd63-53aa-95a3-0cdb28fa8baf]\n",
            "└ @ Base loading.jl:1278\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: CUDA101\n",
            "\u001b[?25l"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "######################################################################### 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: CUDNN_CUDA101\n",
            "\u001b[?25l"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "######################################################################### 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: CUTENSOR_CUDA101\n",
            "\u001b[?25l"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "######################################################################### 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1A\u001b[2K\u001b[?25h"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BenchmarkTools.Trial: \n",
              "  memory estimate:  704 bytes\n",
              "  allocs estimate:  38\n",
              "  --------------\n",
              "  minimum time:     1.162 ms (0.00% GC)\n",
              "  median time:      1.499 ms (0.00% GC)\n",
              "  mean time:        1.506 ms (0.09% GC)\n",
              "  maximum time:     5.156 ms (28.51% GC)\n",
              "  --------------\n",
              "  samples:          3311\n",
              "  evals/sample:     1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gR0rok0y2JeR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42a4cd94-b287-4e21-c60c-1a05fe1f5c6d"
      },
      "source": [
        "CUDA.memory_status()\n",
        "GC.gc(true)\n",
        "CUDA.memory_status()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Effective GPU memory usage: 99.95% (14.719 GiB/14.726 GiB)\n",
            "CUDA allocator usage: 14.547 GiB\n",
            "binned usage: 14.516 GiB (32 bytes allocated, 14.516 GiB cached)\n",
            "Discrepancy of 32.000 MiB between memory pool and allocator!\n",
            "Effective GPU memory usage: 99.95% (14.719 GiB/14.726 GiB)\n",
            "CUDA allocator usage: 14.547 GiB\n",
            "binned usage: 14.531 GiB (16 bytes allocated, 14.531 GiB cached)\n",
            "Discrepancy of 16.000 MiB between memory pool and allocator!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vD2UftRPetCK"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYB2pFH0r9vG",
        "outputId": "5e59d370-fa27-4c68-e92a-5eda34b92603",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Detecting memory leaks\n",
        "\n",
        "## TODO for some reason the logging doesn't show the debug message!!!\n",
        "#  The debug messages from memory_status shows the leaks. \n",
        "#  figure out how to trun them on in the notebook\n",
        "\n",
        "CuArray([1])\n",
        "\n",
        "CUDA.memory_status()\n",
        "\n",
        "####running Julia on debug level 2 or higher (i.e., with the -g2 argument). When you do so, the memory_status() function from above will display additional information:"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Effective GPU memory usage: 1.27% (191.875 MiB/14.726 GiB)\n",
            "CUDA allocator usage: 16.000 MiB\n",
            "binned usage: 80 bytes (80 bytes allocated, 0 bytes cached)\n",
            "Discrepancy of 16.000 MiB between memory pool and allocator!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRA5th0WsADs",
        "outputId": "db73b771-cdd7-4f30-893e-a102e8b1d5de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "@debug \"debug level log msg, before logger change\"\n",
        "@info \"info level msg\"\n",
        "logger = SimpleLogger(stdout, Logging.Debug)\n",
        "old_logger = global_logger(logger) \n",
        "@debug \"debug level log msg, after logger change\"\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "┌ Info: info level msg\n",
            "└ @ Main In[62]:2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QYROWEh0bTT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}